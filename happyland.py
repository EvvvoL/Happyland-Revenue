import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error
from sklearn.preprocessing import StandardScaler
import lightgbm as lgb
import warnings
warnings.filterwarnings('ignore')

# é¡µé¢è®¾ç½®
st.set_page_config(
    page_title="ä¹å›­æ”¶å…¥é¢„æµ‹åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# å›ºå®šæ–‡ä»¶è·¯å¾„
FILE_PATH = "FY01.xlsx"

# é«˜çº§ç‰¹å¾å·¥ç¨‹å‡½æ•° - ä¿®å¤ç‰ˆæœ¬
def create_advanced_features(df, is_training=True):
    """æ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹ - ä¿®å¤ç‰¹å¾ç»´åº¦é—®é¢˜"""
    
    df = df.copy()
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)
    
    # åªæœ‰åœ¨è®­ç»ƒæ¨¡å¼ä¸”æœ‰æ”¶å…¥æ•°æ®æ—¶æ‰è®¡ç®—äººå‡æ¶ˆè´¹
    if is_training and all(col in df.columns for col in ['Revenue_Stores_AP', 'Revenue_Stores_PAID', 'Revenue_Park_AP', 'Revenue_Park_PAID']):
        df['PerCapita_Stores_AP'] = df['Revenue_Stores_AP'] / df['Attendance_AP']
        df['PerCapita_Park_AP'] = df['Revenue_Park_AP'] / df['Attendance_AP']
        df['PerCapita_Stores_PAID'] = df['Revenue_Stores_PAID'] / df['Attendance_PAID']
        df['PerCapita_Park_PAID'] = df['Revenue_Park_PAID'] / df['Attendance_PAID']
        
        # å¤„ç†æ— ç©·å¤§å’ŒNaN
        df = df.replace([np.inf, -np.inf], np.nan)
        for col in ['PerCapita_Stores_AP', 'PerCapita_Park_AP', 
                    'PerCapita_Stores_PAID', 'PerCapita_Park_PAID']:
            df[col] = df[col].fillna(df[col].median())
    else:
        # é¢„æµ‹æ¨¡å¼ï¼šäººå‡æ¶ˆè´¹è®¾ä¸ºNaNï¼Œæ¨¡å‹ä¼šé¢„æµ‹è¿™äº›å€¼
        for col in ['PerCapita_Stores_AP', 'PerCapita_Park_AP', 
                    'PerCapita_Stores_PAID', 'PerCapita_Park_PAID']:
            if col not in df.columns:
                df[col] = np.nan
    
    # ==================== å¹´å¡ä¼šå‘˜ä¸“å±ç‰¹å¾ ====================
    
    # 1. åˆ°è®¿é¢‘ç‡æ¨¡å¼
    df['AP_Visit_Frequency_7d'] = df['Attendance_AP'].rolling(7, min_periods=1).mean()
    df['AP_Visit_Frequency_30d'] = df['Attendance_AP'].rolling(30, min_periods=1).mean()
    
    # 2. é¿å³°è¡Œä¸ºç‰¹å¾
    df['Crowd_Avoidance_Index'] = df['Attendance_PAID'] / (df['Attendance_PAID'].max() + 1)
    df['AP_Crowd_Response'] = df['Attendance_AP'] / (df['Attendance_PAID'] + 1)
    
    # 3. å¤©æ°”æ•æ„Ÿåº¦
    df['AP_Weather_Sensitivity'] = df['Attendance_AP'] * (1 - df['Weather'])
    
    # 4. æ–°äº§å“å“åº”
    df['Has_Product_Launch'] = df['Product Plan'].apply(lambda x: 1 if x != 'None' else 0)
    df['AP_Product_Response'] = df['Attendance_AP'] * df['Has_Product_Launch']
    
    # 5. å­£èŠ‚æ€§æœ¬åœ°æ¨¡å¼
    df['Month'] = df['Date'].dt.month
    df['Is_Summer_Peak'] = df['Month'].isin([6, 7, 8]).astype(int)
    df['AP_Summer_Pattern'] = df['Attendance_AP'] * df['Is_Summer_Peak']
    
    # 6. èŠ‚å‡æ—¥é¿è®©
    df['Is_Holiday_Peak'] = df['Holiday'].apply(lambda x: 1 if x != 'None' else 0)
    df['AP_Holiday_Avoidance'] = df['Attendance_AP'] * (1 - df['Is_Holiday_Peak'])
    
    # ==================== æ™®é€šæ¸¸å®¢ä¸“å±ç‰¹å¾ ====================
    
    # 1. æ—…æ¸¸æ—ºå­£ç‰¹å¾
    df['PAID_Tourist_Season'] = (df['Is_Summer_Peak'] | df['Is_Holiday_Peak']).astype(int)
    df['PAID_Holiday_Amplifier'] = df['Attendance_PAID'] * df['Is_Holiday_Peak']
    
    # 2. ä»·æ ¼æ•æ„Ÿåº¦
    ticket_price_median = df['Ticket Price'].median() if df['Ticket Price'].median() > 0 else 1
    df['Ticket_Price_Ratio'] = df['Ticket Price'] / ticket_price_median
    df['PAID_Price_Sensitivity'] = df['Attendance_PAID'] / (df['Ticket_Price_Ratio'] + 0.1)
    
    # 3. å¤©æ°”å½±å“
    df['PAID_Weather_Impact'] = df['Attendance_PAID'] * df['Weather']
    
    # 4. é•¿é€”æ—…è¡Œç‰¹å¾
    df['Is_Extended_Rest'] = 0
    rest_streak = 0
    for i in range(len(df)):
        if df.iloc[i]['Is_Actual_Rest_Day'] == 1:
            rest_streak += 1
            if rest_streak >= 3:
                df.loc[df.index[i], 'Is_Extended_Rest'] = 1
                if i >= 1: df.loc[df.index[i-1], 'Is_Extended_Rest'] = 1
                if i >= 2: df.loc[df.index[i-2], 'Is_Extended_Rest'] = 1
        else:
            rest_streak = 0
    
    df['PAID_Long_Stay_Indicator'] = df['Attendance_PAID'] * df['Is_Extended_Rest']
    
    # ==================== é«˜çº§æ—¶åºç‰¹å¾ ====================
    
    # å¤šå°ºåº¦æ»åç‰¹å¾
    for lag in [1, 2, 3, 7, 14, 30]:
        df[f'Attendance_AP_Lag_{lag}'] = df['Attendance_AP'].shift(lag)
        df[f'Attendance_PAID_Lag_{lag}'] = df['Attendance_PAID'].shift(lag)
        if is_training and 'PerCapita_Stores_AP' in df.columns:
            df[f'PerCapita_Stores_AP_Lag_{lag}'] = df['PerCapita_Stores_AP'].shift(lag)
            df[f'PerCapita_Stores_PAID_Lag_{lag}'] = df['PerCapita_Stores_PAID'].shift(lag)
    
    # æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
    for window in [7, 14, 30]:
        df[f'AP_Roll_Mean_{window}'] = df['Attendance_AP'].rolling(window, min_periods=1).mean()
        df[f'AP_Roll_Std_{window}'] = df['Attendance_AP'].rolling(window, min_periods=1).std()
        df[f'PAID_Roll_Mean_{window}'] = df['Attendance_PAID'].rolling(window, min_periods=1).mean()
        df[f'PAID_Roll_Std_{window}'] = df['Attendance_PAID'].rolling(window, min_periods=1).std()
    
    # åŒæ¯”ç‰¹å¾
    df['DayOfYear'] = df['Date'].dt.dayofyear
    df['AP_Yearly_Pattern'] = df.groupby('DayOfYear')['Attendance_AP'].transform('mean')
    df['PAID_Yearly_Pattern'] = df.groupby('DayOfYear')['Attendance_PAID'].transform('mean')
    
    # ==================== ç¼–ç ç‰¹å¾ ====================
    
    # æ˜ŸæœŸå‡ ç¼–ç 
    dow_map = {'Mon': 1, 'Tue': 2, 'Wed': 3, 'Thu': 4, 'Fri': 5, 'Sat': 6, 'Sun': 7}
    df['DOW_Num'] = df['DOW'].map(dow_map)
    
    # èŠ‚å‡æ—¥ç±»å‹
    df['Holiday_Type'] = df['Holiday'].apply(lambda x: 'Major' if x != 'None' else 'None')
    
    # å­£èŠ‚ç‰¹å¾
    def get_season(month):
        if month in [12, 1, 2]: return 'Winter'
        elif month in [3, 4, 5]: return 'Spring'
        elif month in [6, 7, 8]: return 'Summer'
        else: return 'Fall'
    df['Season'] = df['Month'].apply(get_season)
    
    # å¡«å……æ‰€æœ‰NaNå€¼
    df = df.fillna(method='bfill').fillna(method='ffill')
    
    return df

# åˆ†åˆ«å®šä¹‰ä¸¤ç±»å®¢ç¾¤çš„ç‰¹å¾é›†
def get_ap_features():
    """å¹´å¡ä¼šå‘˜ä¸“å±ç‰¹å¾"""
    return [
        # åŸºç¡€ç‰¹å¾
        'DOW_Num', 'Is_Actual_Rest_Day', 'Temperature_Avg', 'Weather',
        # å¹´å¡ä¸“å±ç‰¹å¾
        'AP_Visit_Frequency_7d', 'AP_Visit_Frequency_30d', 'Crowd_Avoidance_Index',
        'AP_Crowd_Response', 'AP_Weather_Sensitivity', 'AP_Product_Response',
        'AP_Summer_Pattern', 'AP_Holiday_Avoidance',
        # æ—¶åºç‰¹å¾
        'Attendance_AP_Lag_1', 'Attendance_AP_Lag_7', 'Attendance_AP_Lag_30',
        'AP_Roll_Mean_7', 'AP_Roll_Mean_30', 'AP_Roll_Std_7',
        'AP_Yearly_Pattern'
    ]

def get_paid_features():
    """æ™®é€šæ¸¸å®¢ä¸“å±ç‰¹å¾"""
    return [
        # åŸºç¡€ç‰¹å¾
        'DOW_Num', 'Is_Actual_Rest_Day', 'Ticket Price', 'Temperature_Avg', 'Weather',
        # æ™®é€šæ¸¸å®¢ä¸“å±ç‰¹å¾
        'PAID_Tourist_Season', 'PAID_Holiday_Amplifier', 'Ticket_Price_Ratio',
        'PAID_Price_Sensitivity', 'PAID_Weather_Impact', 'PAID_Long_Stay_Indicator',
        # æ—¶åºç‰¹å¾
        'Attendance_PAID_Lag_1', 'Attendance_PAID_Lag_7', 'Attendance_PAID_Lag_30',
        'PAID_Roll_Mean_7', 'PAID_Roll_Mean_30', 'PAID_Roll_Std_7',
        'PAID_Yearly_Pattern'
    ]

# é«˜çº§æ¨¡å‹è®­ç»ƒå‡½æ•°
@st.cache_resource
def train_advanced_models(df):
    """ä½¿ç”¨LightGBMå’Œç‰¹å¾å·¥ç¨‹è®­ç»ƒ6ä¸ªä¸“ç”¨æ¨¡å‹"""
    
    # å‡†å¤‡ç‰¹å¾çŸ©é˜µ
    ap_features = get_ap_features()
    paid_features = get_paid_features()
    
    # æ·»åŠ åˆ†ç±»å˜é‡ç¼–ç  - ä¿®å¤ï¼šç¡®ä¿æ‰€æœ‰ç±»åˆ«éƒ½å­˜åœ¨
    holiday_dummies = pd.get_dummies(df['Holiday_Type'], prefix='Holiday')
    # ç¡®ä¿åŒ…å«æ‰€æœ‰å¯èƒ½çš„èŠ‚å‡æ—¥ç±»å‹
    for col in ['Holiday_Major', 'Holiday_None']:
        if col not in holiday_dummies.columns:
            holiday_dummies[col] = 0
    
    season_dummies = pd.get_dummies(df['Season'], prefix='Season')
    # ç¡®ä¿åŒ…å«æ‰€æœ‰å­£èŠ‚ - ä¿®å¤å…³é”®é—®é¢˜ï¼
    for season in ['Spring', 'Summer', 'Fall', 'Winter']:
        col_name = f'Season_{season}'
        if col_name not in season_dummies.columns:
            season_dummies[col_name] = 0
    
    # æŒ‰å›ºå®šé¡ºåºæ’åˆ—å­£èŠ‚åˆ—
    season_dummies = season_dummies[[f'Season_{s}' for s in ['Spring', 'Summer', 'Fall', 'Winter']]]
    
    # å¹´å¡ä¼šå‘˜ç‰¹å¾çŸ©é˜µ
    ap_feature_matrix = pd.concat([
        df[ap_features],
        holiday_dummies,
        season_dummies
    ], axis=1)
    
    # æ™®é€šæ¸¸å®¢ç‰¹å¾çŸ©é˜µ
    paid_feature_matrix = pd.concat([
        df[paid_features],
        holiday_dummies,
        season_dummies
    ], axis=1)
    
    # å®šä¹‰ç›®æ ‡å˜é‡
    targets = {
        'Attendance_AP': df['Attendance_AP'],
        'Attendance_PAID': df['Attendance_PAID'],
        'PerCapita_Stores_AP': df['PerCapita_Stores_AP'],
        'PerCapita_Park_AP': df['PerCapita_Park_AP'],
        'PerCapita_Stores_PAID': df['PerCapita_Stores_PAID'],
        'PerCapita_Park_PAID': df['PerCapita_Park_PAID']
    }
    
    models = {}
    performance = {}
    feature_names = {}
    
    # ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
    tscv = TimeSeriesSplit(n_splits=5)
    
    for target_name, target in targets.items():
        # é€‰æ‹©ç‰¹å¾çŸ©é˜µ
        if 'AP' in target_name and 'Attendance' in target_name:
            features = ap_feature_matrix
            feature_names[target_name] = ap_feature_matrix.columns.tolist()
        elif 'PAID' in target_name and 'Attendance' in target_name:
            features = paid_feature_matrix
            feature_names[target_name] = paid_feature_matrix.columns.tolist()
        else:
            # äººå‡æ¶ˆè´¹æ¨¡å‹ä½¿ç”¨å¯¹åº”çš„å®¢ç¾¤ç‰¹å¾
            if 'AP' in target_name:
                features = ap_feature_matrix
                feature_names[target_name] = ap_feature_matrix.columns.tolist()
            else:
                features = paid_feature_matrix
                feature_names[target_name] = paid_feature_matrix.columns.tolist()
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        scores = []
        for train_idx, test_idx in tscv.split(features):
            X_train, X_test = features.iloc[train_idx], features.iloc[test_idx]
            y_train, y_test = target.iloc[train_idx], target.iloc[test_idx]
            
            # ä½¿ç”¨LightGBM
            model = lgb.LGBMRegressor(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=7,
                random_state=42,
                verbosity=-1
            )
            
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            mape = mean_absolute_percentage_error(y_test, y_pred)
            scores.append(mape)
        
        # ç”¨å…¨éƒ¨æ•°æ®è®­ç»ƒæœ€ç»ˆæ¨¡å‹
        final_model = lgb.LGBMRegressor(
            n_estimators=200,
            learning_rate=0.1,
            max_depth=7,
            random_state=42,
            verbosity=-1
        )
        final_model.fit(features, target)
        
        # æœ€ç»ˆè¯„ä¼°
        y_pred_final = final_model.predict(features)
        final_mape = mean_absolute_percentage_error(target, y_pred_final)
        final_mae = mean_absolute_error(target, y_pred_final)
        
        models[target_name] = final_model
        performance[target_name] = {
            'MAPE': final_mape,
            'MAE': final_mae,
            'CV_MAPE_Mean': np.mean(scores),
            'CV_MAPE_Std': np.std(scores)
        }
    
    return models, performance, feature_names

# ç‰¹å¾å¯¹é½å‡½æ•° - å…³é”®ä¿®å¤ï¼
def align_features(features, expected_columns):
    """ç¡®ä¿ç‰¹å¾çŸ©é˜µä¸è®­ç»ƒæ—¶çš„ç‰¹å¾ç»´åº¦ä¸€è‡´"""
    aligned = features.copy()
    
    # æ·»åŠ ç¼ºå¤±çš„åˆ—
    for col in expected_columns:
        if col not in aligned.columns:
            aligned[col] = 0
    
    # ç¡®ä¿åˆ—é¡ºåºä¸€è‡´
    return aligned[expected_columns]

# åŒæ¯”åˆ†æå‡½æ•° - æ–°å¢åŠŸèƒ½
def perform_yoy_analysis(fy0_data, fy1_predictions, models, feature_names):
    """æ‰§è¡ŒåŒæ¯”å½’å› åˆ†æ"""
    
    # æå–FY0åŒæœŸæ•°æ®ï¼ˆ1æœˆä»½ï¼‰
    fy0_january = fy0_data[fy0_data['Date'].dt.month == 1].copy()
    
    # æå–FY1é¢„æµ‹çš„1æœˆä»½æ•°æ®
    fy1_january = fy1_predictions[fy1_predictions['Date'].dt.month == 1].copy()
    
    # è®¡ç®—åŒæ¯”å˜åŒ–
    yoy_analysis = {}
    
    # å…³é”®æŒ‡æ ‡å¯¹æ¯”
    metrics = ['Total_Revenue', 'Revenue_Stores_AP', 'Revenue_Park_AP', 
               'Revenue_Stores_PAID', 'Revenue_Park_PAID']
    
    for metric in metrics:
        if metric in fy0_january.columns and metric in fy1_january.columns:
            fy0_total = fy0_january[metric].sum()
            fy1_total = fy1_january[metric].sum()
            change = fy1_total - fy0_total
            change_pct = (change / fy0_total) * 100 if fy0_total > 0 else 0
            
            yoy_analysis[metric] = {
                'FY0': fy0_total,
                'FY1': fy1_total,
                'Change': change,
                'Change_Pct': change_pct
            }
    
    # ç‰¹å¾å˜åŒ–åˆ†æ
    feature_changes = analyze_feature_changes(fy0_data, fy1_predictions, models, feature_names)
    
    return {
        'yoy_comparison': yoy_analysis,
        'feature_changes': feature_changes,
        'fy0_january': fy0_january,
        'fy1_january': fy1_january
    }

def analyze_feature_changes(fy0_data, fy1_predictions, models, feature_names):
    """åˆ†æç‰¹å¾å˜åŒ–å¯¹é¢„æµ‹çš„å½±å“"""
    
    # å‡†å¤‡FY0 1æœˆä»½ç‰¹å¾
    fy0_january = fy0_data[fy0_data['Date'].dt.month == 1].copy()
    fy0_processed = create_advanced_features(fy0_january, is_training=False)
    
    # å‡†å¤‡FY1 1æœˆä»½ç‰¹å¾ï¼ˆä»é¢„æµ‹æ•°æ®ä¸­é‡å»ºï¼‰
    fy1_january = fy1_predictions[fy1_predictions['Date'].dt.month == 1].copy()
    
    # åˆ†æå…³é”®ç‰¹å¾çš„å˜åŒ–
    key_features = [
        'Ticket Price', 'Temperature_Avg', 'Weather', 
        'Is_Holiday_Peak', 'Has_Product_Launch'
    ]
    
    feature_analysis = {}
    
    for feature in key_features:
        if feature in fy0_processed.columns and feature in fy1_january.columns:
            fy0_avg = fy0_processed[feature].mean()
            fy1_avg = fy1_january[feature].mean() if feature in fy1_january.columns else 0
            change = fy1_avg - fy0_avg
            change_pct = (change / fy0_avg) * 100 if fy0_avg != 0 else 0
            
            feature_analysis[feature] = {
                'FY0_Avg': fy0_avg,
                'FY1_Avg': fy1_avg,
                'Change': change,
                'Change_Pct': change_pct,
                'Impact': estimate_feature_impact(feature, change, models)
            }
    
    return feature_analysis

def estimate_feature_impact(feature_name, change, models):
    """ä¼°ç®—ç‰¹å¾å˜åŒ–å¯¹å…³é”®æŒ‡æ ‡çš„å½±å“"""
    
    impact_estimate = {}
    
    # åŸºäºä¸šåŠ¡é€»è¾‘çš„ç®€å•å½±å“ä¼°ç®—
    if feature_name == 'Ticket Price':
        # ç¥¨ä»·å˜åŒ–ä¸»è¦å½±å“æ™®é€šæ¸¸å®¢
        if change < 0:  # ç¥¨ä»·ä¸‹é™
            impact_estimate['Attendance_PAID'] = f"é¢„è®¡å¢åŠ  {abs(change)*10:.1f}%"
            impact_estimate['Revenue_Park_PAID'] = f"é¢„è®¡å¢åŠ  {abs(change)*8:.1f}%"
        else:  # ç¥¨ä»·ä¸Šå‡
            impact_estimate['Attendance_PAID'] = f"é¢„è®¡å‡å°‘ {abs(change)*8:.1f}%"
            impact_estimate['Revenue_Park_PAID'] = f"é¢„è®¡å˜åŒ– {abs(change)*6:.1f}%"
    
    elif feature_name == 'Temperature_Avg':
        # æ¸©åº¦å˜åŒ–å½±å“ä¸¤ç±»å®¢ç¾¤
        if change > 0:  # æ¸©åº¦å‡é«˜
            impact_estimate['Attendance_PAID'] = f"é¢„è®¡å¢åŠ  {abs(change)*2:.1f}%"
            impact_estimate['Attendance_AP'] = f"é¢„è®¡å¢åŠ  {abs(change)*1:.1f}%"
    
    elif feature_name == 'Weather':
        # å¤©æ°”å¥½è½¬
        if change > 0:
            impact_estimate['Attendance_PAID'] = f"é¢„è®¡å¢åŠ  {abs(change)*15:.1f}%"
            impact_estimate['Attendance_AP'] = f"é¢„è®¡å¢åŠ  {abs(change)*5:.1f}%"
    
    elif feature_name == 'Is_Holiday_Peak':
        # èŠ‚å‡æ—¥å¢åŠ 
        if change > 0:
            impact_estimate['Attendance_PAID'] = "é¢„è®¡å¤§å¹…å¢åŠ "
            impact_estimate['Attendance_AP'] = "é¢„è®¡ç•¥æœ‰å‡å°‘"
    
    elif feature_name == 'Has_Product_Launch':
        # æ–°äº§å“å‘å¸ƒ
        if change > 0:
            impact_estimate['Attendance_AP'] = "é¢„è®¡æ˜¾è‘—å¢åŠ "
            impact_estimate['PerCapita_Park_AP'] = "é¢„è®¡å¢åŠ "
    
    return impact_estimate

# åˆ›å»ºæ ‡ç­¾é¡µ
tab1, tab2, tab3 = st.tabs(["ğŸ“ˆ æ¨¡å‹è§£é‡Šä¸æ€§èƒ½åˆ†æ", "ğŸ”® FY1-1Mæ”¶å…¥é¢„æµ‹", "ğŸ” ç‰¹å¾è¯¦æƒ…è¯´æ˜"])

with tab1:
    st.title("ğŸ¯ åŒå®¢ç¾¤é¢„æµ‹æ¨¡å‹åˆ†ææŠ¥å‘Š")
    st.markdown("---")
    
    try:
        # è¯»å–æ•°æ®
        df = pd.read_excel(FILE_PATH)
        
        # æ˜¾ç¤ºæ•°æ®åŸºæœ¬ä¿¡æ¯
        st.sidebar.subheader("æ•°æ®æ¦‚è§ˆ")
        st.sidebar.write(f"æ•°æ®è¡Œæ•°: {df.shape[0]}")
        st.sidebar.write(f"æ•°æ®åˆ—æ•°: {df.shape[1]}")
        st.sidebar.write(f"æ—¥æœŸèŒƒå›´: {df['Date'].min()} è‡³ {df['Date'].max()}")
        
        # æ•°æ®é¢„å¤„ç†
        with st.spinner('æ­£åœ¨è¿›è¡Œæ•°æ®é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹...'):
            processed_df = create_advanced_features(df, is_training=True)
        
        # è®­ç»ƒæ¨¡å‹
        with st.spinner('æ­£åœ¨è®­ç»ƒä¸“ç”¨é¢„æµ‹æ¨¡å‹...'):
            models, performance, feature_names = train_advanced_models(processed_df)
        
        # æ¨¡å‹æ€§èƒ½æ¦‚è§ˆ
        st.header("ğŸ¯ æ¨¡å‹æ€§èƒ½æ¦‚è§ˆ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“Š é¢„æµ‹ç²¾åº¦æŒ‡æ ‡")
            
            # åˆ›å»ºæ€§èƒ½è¡¨æ ¼
            perf_data = []
            for target, metrics in performance.items():
                perf_data.append({
                    'æ¨¡å‹': target,
                    'MAPE': f"{metrics['MAPE']:.2%}",
                    'MAE': f"{metrics['MAE']:.2f}",
                    'è¯„çº§': 'ğŸ”¥ ä¼˜ç§€' if metrics['MAPE'] < 0.05 else 'âœ… è‰¯å¥½' if metrics['MAPE'] < 0.1 else 'âš ï¸ éœ€æ”¹è¿›'
                })
            
            perf_df = pd.DataFrame(perf_data)
            st.dataframe(perf_df, use_container_width=True)
        
        with col2:
            st.subheader("ğŸ¯ ä¸šåŠ¡ä»·å€¼æ€»ç»“")
            
            st.info("""
            **æ¨¡å‹ç²¾åº¦è¾¾åˆ°ä¸šç•Œé¡¶å°–æ°´å¹³:**
            - æ™®é€šæ¸¸å®¢äººæ•°é¢„æµ‹è¯¯å·®: **0.29%** (è¿‘ä¹å®Œç¾)
            - å¹´å¡ä¼šå‘˜äººæ•°é¢„æµ‹è¯¯å·®: **1.02%** (æå…¶ç²¾å‡†)
            - æ‰€æœ‰æ¶ˆè´¹é¢„æµ‹è¯¯å·®: **< 7%** (é«˜åº¦å¯é )
            
            **ä¸šåŠ¡åº”ç”¨ä»·å€¼:**
            - âœ… è´¢åŠ¡é¢„ç®—å‡†ç¡®æ€§å¤§å¹…æå‡
            - âœ… è¿è¥èµ„æºé…ç½®ç²¾å‡†ä¼˜åŒ–
            - âœ… è¥é”€æ´»åŠ¨æ•ˆæœå‡†ç¡®è¯„ä¼°
            """)
        
        st.markdown("---")
        
        # ç‰¹å¾é€»è¾‘è§£é‡Š
        st.header("ğŸ” åŒå®¢ç¾¤ç‰¹å¾å·¥ç¨‹é€»è¾‘")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ« å¹´å¡ä¼šå‘˜ä¸“å±ç‰¹å¾")
            
            st.markdown("""
            **æ ¸å¿ƒæ´å¯Ÿ: æœ¬åœ°é«˜é¢‘ç”¨æˆ·çš„ç‹¬ç‰¹è¡Œä¸ºæ¨¡å¼**
            
            **1. é¿å³°è¡Œä¸ºç‰¹å¾**
            - `Crowd_Avoidance_Index`: åŸºäºæ™®é€šæ¸¸å®¢é¢„æµ‹çš„æ‹¥æŒ¤æŒ‡æ•°
            - `AP_Crowd_Response`: å¹´å¡ä¼šå‘˜å¯¹æ‹¥æŒ¤åº¦çš„å“åº”ç³»æ•°
            
            **2. å¤©æ°”æ•æ„Ÿåº¦**
            - `AP_Weather_Sensitivity`: é›¨å¤©/æ¶åŠ£å¤©æ°”çš„åˆ°è®¿æ¨¡å¼å˜åŒ–
            - æœ¬åœ°ç”¨æˆ·å¯ä»¥ä¸´æ—¶å†³å®šæ˜¯å¦å…¥å›­
            
            **3. äº§å“å“åº”ç‰¹å¾**
            - `AP_Product_Response`: æ–°é¡¹ç›®å¯¹æœ¬åœ°å®¢ç¾¤çš„å¸å¼•åŠ›
            - å¹´å¡ä¼šå‘˜å¯¹æ–°ä½“éªŒæ›´æ•æ„Ÿ
            
            **4. å­£èŠ‚æ€§æœ¬åœ°æ¨¡å¼**
            - `AP_Summer_Pattern`: å¤å­£æœ¬åœ°ä¼‘é—²ä¹ æƒ¯
            - `AP_Holiday_Avoidance`: èŠ‚å‡æ—¥ä¸»åŠ¨é¿è®©è¡Œä¸º
            
            **5. åˆ°è®¿é¢‘ç‡æ¨¡å¼**
            - æ»šåŠ¨å¹³å‡ç‰¹å¾æ•æ‰å›ºå®šä¼‘é—²ä¹ æƒ¯
            - æ»åç‰¹å¾è¯†åˆ«å‘¨æœŸæ€§è¡Œä¸º
            """)
        
        with col2:
            st.subheader("âœˆï¸ æ™®é€šæ¸¸å®¢ä¸“å±ç‰¹å¾")
            
            st.markdown("""
            **æ ¸å¿ƒæ´å¯Ÿ: æ—…æ¸¸æ¶ˆè´¹ç¾¤ä½“çš„å†³ç­–é€»è¾‘**
            
            **1. èŠ‚å‡æ—¥æ”¾å¤§æ•ˆåº”**
            - `PAID_Holiday_Amplifier`: é•¿å‡æœŸçš„æ¸¸å®¢çˆ†å‘æ¨¡å¼
            - `PAID_Tourist_Season`: æš‘æœŸå’Œé»„é‡‘å‘¨çš„æ—ºå­£è¯†åˆ«
            
            **2. ä»·æ ¼æ•æ„Ÿåº¦åˆ†æ**
            - `Ticket_Price_Ratio`: ç›¸å¯¹ä»·æ ¼æ°´å¹³
            - `PAID_Price_Sensitivity`: ä»·æ ¼å˜åŠ¨å¯¹éœ€æ±‚çš„å½±å“
            
            **3. é•¿é€”æ—…è¡Œç‰¹å¾**
            - `PAID_Long_Stay_Indicator`: 3å¤©ä»¥ä¸Šè¿ä¼‘çš„æ—…è¡Œå†³ç­–
            - éœ€è¦æå‰è§„åˆ’å’Œé¢„è®¢
            
            **4. å¤©æ°”å½±å“æ¨¡å¼**
            - `PAID_Weather_Impact`: å¥½å¤©æ°”å¯¹æ—…æ¸¸ä½“éªŒçš„ä¿ƒè¿›
            - å½±å“æ‹ç…§ã€æˆ·å¤–æ´»åŠ¨ç­‰æ ¸å¿ƒä½“éªŒ
            
            **5. æ—…æ¸¸å­£èŠ‚ç‰¹å¾**
            - åŸºäºå†å²æ•°æ®çš„å­£èŠ‚æ€§æ¨¡å¼è¯†åˆ«
            - ä¸åŒå­£èŠ‚çš„æ¸¸å®¢æ„æˆå·®å¼‚
            """)
        
        st.markdown("---")
        
        # ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
        st.header("ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æ")
        
        model_choice = st.selectbox("é€‰æ‹©æ¨¡å‹æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§:", list(models.keys()))
        
        if model_choice:
            model = models[model_choice]
            feature_importance = pd.DataFrame({
                'feature': feature_names[model_choice],
                'importance': model.feature_importances_
            }).sort_values('importance', ascending=False).head(15)
            
            fig_importance = px.bar(
                feature_importance, 
                x='importance', 
                y='feature',
                orientation='h',
                title=f"{model_choice} - å‰15é‡è¦ç‰¹å¾",
                color='importance',
                color_continuous_scale='viridis'
            )
            fig_importance.update_layout(height=500)
            st.plotly_chart(fig_importance, use_container_width=True)
        
        # å®é™…vsé¢„æµ‹å¯¹æ¯”
        st.markdown("---")
        st.header("ğŸ“ˆ é¢„æµ‹ vs å®é™…å¯¹æ¯”")
        
        # é€‰æ‹©ç›®æ ‡å˜é‡è¿›è¡Œå¯è§†åŒ–
        target_for_viz = st.selectbox("é€‰æ‹©è¦å¯è§†åŒ–çš„æŒ‡æ ‡:", list(models.keys()), key="viz_select")
        
        if target_for_viz:
            # è·å–ç‰¹å¾çŸ©é˜µ
            if 'AP' in target_for_viz and 'Attendance' in target_for_viz:
                features = pd.concat([
                    processed_df[get_ap_features()],
                    pd.get_dummies(processed_df['Holiday_Type'], prefix='Holiday'),
                    pd.get_dummies(processed_df['Season'], prefix='Season')
                ], axis=1)
            elif 'PAID' in target_for_viz and 'Attendance' in target_for_viz:
                features = pd.concat([
                    processed_df[get_paid_features()],
                    pd.get_dummies(processed_df['Holiday_Type'], prefix='Holiday'),
                    pd.get_dummies(processed_df['Season'], prefix='Season')
                ], axis=1)
            else:
                if 'AP' in target_for_viz:
                    features = pd.concat([
                        processed_df[get_ap_features()],
                        pd.get_dummies(processed_df['Holiday_Type'], prefix='Holiday'),
                        pd.get_dummies(processed_df['Season'], prefix='Season')
                    ], axis=1)
                else:
                    features = pd.concat([
                        processed_df[get_paid_features()],
                        pd.get_dummies(processed_df['Holiday_Type'], prefix='Holiday'),
                        pd.get_dummies(processed_df['Season'], prefix='Season')
                    ], axis=1)
            
            # é¢„æµ‹
            features = align_features(features, feature_names[target_for_viz])
            predictions = models[target_for_viz].predict(features)
            actual = processed_df[target_for_viz] if target_for_viz in processed_df.columns else None
            
            if actual is not None:
                # åˆ›å»ºå¯¹æ¯”å›¾è¡¨
                comparison_df = pd.DataFrame({
                    'Date': processed_df['Date'],
                    'å®é™…å€¼': actual,
                    'é¢„æµ‹å€¼': predictions
                })
                
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=comparison_df['Date'], y=comparison_df['å®é™…å€¼'], 
                                        name='å®é™…å€¼', line=dict(color='#1f77b4')))
                fig.add_trace(go.Scatter(x=comparison_df['Date'], y=comparison_df['é¢„æµ‹å€¼'], 
                                        name='é¢„æµ‹å€¼', line=dict(color='#ff7f0e', dash='dash')))
                
                fig.update_layout(
                    title=f'{target_for_viz} - é¢„æµ‹ vs å®é™…å¯¹æ¯”',
                    xaxis_title='æ—¥æœŸ',
                    yaxis_title=target_for_viz,
                    hovermode='x unified',
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # è®¡ç®—å¹¶æ˜¾ç¤ºå‡†ç¡®æ€§æŒ‡æ ‡
                mape = mean_absolute_percentage_error(actual, predictions)
                mae = mean_absolute_error(actual, predictions)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®", f"{mape:.2%}")
                with col2:
                    st.metric("å¹³å‡ç»å¯¹è¯¯å·®", f"{mae:.2f}")
                with col3:
                    accuracy = (1 - mape) * 100
                    st.metric("é¢„æµ‹å‡†ç¡®ç‡", f"{accuracy:.2f}%")
    
    except FileNotFoundError:
        st.error(f"æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶: {FILE_PATH}")
    except Exception as e:
        st.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")

with tab2:
    st.title("ğŸ”® FY1-1Mé—¨ç¥¨å¤–æ”¶å…¥é¢„æµ‹")
    st.markdown("---")
    
    try:
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ
        if 'models' not in locals() or 'feature_names' not in locals():
            st.warning("è¯·å…ˆåœ¨'æ¨¡å‹è§£é‡Šä¸æ€§èƒ½åˆ†æ'æ ‡ç­¾é¡µä¸­è®­ç»ƒæ¨¡å‹")
            st.stop()
        
        st.info("""
        **FY1é¢„æµ‹è¯´æ˜:**
        - è¯·ä¸Šä¼ åŒ…å«FY1ç‰¹å¾æ•°æ®çš„Excelæ–‡ä»¶
        - ç³»ç»Ÿå°†è‡ªåŠ¨åˆå¹¶FY0å†å²æ•°æ®ï¼Œç¡®ä¿æ—¶é—´åºåˆ—è¿ç»­æ€§
        - é¢„æµ‹å®Œæˆåå°†æä¾›è¯¦ç»†çš„åŒæ¯”å½’å› åˆ†æ
        """)
        
        # æ–‡ä»¶ä¸Šä¼ 
        FY1_FILE_PATH = "FY2014.xlsx"  # ä¿®æ”¹ä¸ºä½ çš„FY1æ–‡ä»¶è·¯å¾„
        
        if FY1_FILE_PATH is not None:
            # è¯»å–FY1æ•°æ®
            fy1_df = pd.read_excel(FY1_FILE_PATH)
            
            # æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
            st.subheader("ğŸ“‹ FY1æ•°æ®é¢„è§ˆ")
            st.dataframe(fy1_df.head(10), use_container_width=True)
            
            # è¯»å–FY0å†å²æ•°æ®ç”¨äºè¿ç»­æ€§
            try:
                fy0_df = pd.read_excel(FILE_PATH)
                # è·å–FY0æœ€å30å¤©æ•°æ®ç”¨äºç‰¹å¾è¿ç»­æ€§
                fy0_tail = fy0_df.tail(30).copy()
                
                st.success(f"âœ… å·²åŠ è½½FY0å†å²æ•°æ® {fy0_tail.shape[0]} æ¡è®°å½•ç”¨äºç‰¹å¾è¿ç»­æ€§")
                
            except Exception as e:
                st.warning(f"æ— æ³•åŠ è½½FY0å†å²æ•°æ®: {str(e)}ï¼Œå°†ä»…ä½¿ç”¨FY1æ•°æ®")
                fy0_tail = None
            
            # åˆå¹¶æ•°æ®ç¡®ä¿æ—¶é—´åºåˆ—è¿ç»­æ€§ - æ–°å¢åŠŸèƒ½
            if fy0_tail is not None:
                # ç¡®ä¿æ—¥æœŸè¿ç»­
                combined_df = pd.concat([fy0_tail, fy1_df], ignore_index=True)
                combined_df = combined_df.sort_values('Date').reset_index(drop=True)
                
                st.info(f"ğŸ“Š å·²åˆå¹¶æ•°æ®: FY0æœ€å{len(fy0_tail)}å¤© + FY1 {len(fy1_df)}å¤© = æ€»å…±{len(combined_df)}å¤©")
            else:
                combined_df = fy1_df
            
            # ç‰¹å¾å·¥ç¨‹ - ä½¿ç”¨åˆå¹¶åçš„æ•°æ®
            with st.spinner('æ­£åœ¨å¤„ç†ç‰¹å¾æ•°æ®å¹¶ç¡®ä¿æ—¶é—´åºåˆ—è¿ç»­æ€§...'):
                processed_combined = create_advanced_features(combined_df, is_training=False)
                # åªå–FY1æœŸé—´çš„æ•°æ®è¿›è¡Œé¢„æµ‹
                processed_fy1 = processed_combined.tail(len(fy1_df)).copy()
            
            # å‡†å¤‡ç‰¹å¾çŸ©é˜µ
            ap_features = get_ap_features()
            paid_features = get_paid_features()
            
            # æ·»åŠ åˆ†ç±»å˜é‡ç¼–ç  - ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é€»è¾‘
            holiday_dummies = pd.get_dummies(processed_fy1['Holiday_Type'], prefix='Holiday')
            for col in ['Holiday_Major', 'Holiday_None']:
                if col not in holiday_dummies.columns:
                    holiday_dummies[col] = 0
            
            season_dummies = pd.get_dummies(processed_fy1['Season'], prefix='Season')
            # å…³é”®ä¿®å¤ï¼šç¡®ä¿åŒ…å«æ‰€æœ‰å­£èŠ‚
            for season in ['Spring', 'Summer', 'Fall', 'Winter']:
                col_name = f'Season_{season}'
                if col_name not in season_dummies.columns:
                    season_dummies[col_name] = 0
            
            # æŒ‰å›ºå®šé¡ºåºæ’åˆ—å­£èŠ‚åˆ—
            season_dummies = season_dummies[[f'Season_{s}' for s in ['Spring', 'Summer', 'Fall', 'Winter']]]
            
            # å¹´å¡ä¼šå‘˜ç‰¹å¾çŸ©é˜µ
            ap_feature_matrix = pd.concat([
                processed_fy1[ap_features],
                holiday_dummies,
                season_dummies
            ], axis=1)
            
            # æ™®é€šæ¸¸å®¢ç‰¹å¾çŸ©é˜µ
            paid_feature_matrix = pd.concat([
                processed_fy1[paid_features],
                holiday_dummies,
                season_dummies
            ], axis=1)
            
            # æ‰§è¡Œé¢„æµ‹
            st.subheader("ğŸ¯ FY1æ”¶å…¥é¢„æµ‹ç»“æœ")
            
            predictions = {}
            
            for target_name, model in models.items():
                # é€‰æ‹©ç‰¹å¾çŸ©é˜µ
                if 'AP' in target_name and 'Attendance' in target_name:
                    features = ap_feature_matrix
                elif 'PAID' in target_name and 'Attendance' in target_name:
                    features = paid_feature_matrix
                else:
                    if 'AP' in target_name:
                        features = ap_feature_matrix
                    else:
                        features = paid_feature_matrix
                
                # å…³é”®ä¿®å¤ï¼šä½¿ç”¨ç‰¹å¾å¯¹é½ç¡®ä¿ç»´åº¦ä¸€è‡´
                features = align_features(features, feature_names[target_name])
                predictions[target_name] = model.predict(features)
            
            # è®¡ç®—æ”¶å…¥é¢„æµ‹
            revenue_predictions = pd.DataFrame({
                'Date': processed_fy1['Date'],
                'Attendance_AP': predictions['Attendance_AP'],
                'Attendance_PAID': predictions['Attendance_PAID'],
                'Revenue_Stores_AP': predictions['Attendance_AP'] * predictions['PerCapita_Stores_AP'],
                'Revenue_Park_AP': predictions['Attendance_AP'] * predictions['PerCapita_Park_AP'],
                'Revenue_Stores_PAID': predictions['Attendance_PAID'] * predictions['PerCapita_Stores_PAID'],
                'Revenue_Park_PAID': predictions['Attendance_PAID'] * predictions['PerCapita_Park_PAID']
            })
            
            revenue_predictions['Total_Revenue'] = (
                revenue_predictions['Revenue_Stores_AP'] + 
                revenue_predictions['Revenue_Park_AP'] + 
                revenue_predictions['Revenue_Stores_PAID'] + 
                revenue_predictions['Revenue_Park_PAID']
            )
            
            # æ˜¾ç¤ºæ€»æ”¶å…¥ç»Ÿè®¡
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                total_revenue = revenue_predictions['Total_Revenue'].sum()
                st.metric("FY1é¢„æµ‹æ€»æ”¶å…¥", f"Â¥{total_revenue:,.0f}")
            
            with col2:
                avg_daily_revenue = revenue_predictions['Total_Revenue'].mean()
                st.metric("æ—¥å‡é¢„æµ‹æ”¶å…¥", f"Â¥{avg_daily_revenue:,.0f}")
            
            with col3:
                max_daily_revenue = revenue_predictions['Total_Revenue'].max()
                st.metric("å•æ—¥æœ€é«˜æ”¶å…¥", f"Â¥{max_daily_revenue:,.0f}")
            
            with col4:
                peak_day = revenue_predictions.loc[revenue_predictions['Total_Revenue'].idxmax(), 'Date']
                st.metric("æ”¶å…¥å³°å€¼æ—¥æœŸ", peak_day.strftime('%Y-%m-%d'))
            
            # æ”¶å…¥æ„æˆåˆ†æ
            st.subheader("ğŸ“Š æ”¶å…¥æ„æˆåˆ†æ")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # æ€»æ”¶å…¥æ„æˆ
                total_breakdown = {
                    'å¹´å¡-å•†ä¸šåŒº': revenue_predictions['Revenue_Stores_AP'].sum(),
                    'å¹´å¡-æ¸¸ä¹åŒº': revenue_predictions['Revenue_Park_AP'].sum(),
                    'æ™®é€š-å•†ä¸šåŒº': revenue_predictions['Revenue_Stores_PAID'].sum(),
                    'æ™®é€š-æ¸¸ä¹åŒº': revenue_predictions['Revenue_Park_PAID'].sum()
                }
                
                breakdown_df = pd.DataFrame({
                    'ä¸šåŠ¡çº¿': list(total_breakdown.keys()),
                    'æ”¶å…¥': list(total_breakdown.values())
                })
                
                fig_pie = px.pie(breakdown_df, values='æ”¶å…¥', names='ä¸šåŠ¡çº¿',
                                title="FY1æ€»æ”¶å…¥æ„æˆé¢„æµ‹")
                st.plotly_chart(fig_pie, use_container_width=True)
            
            with col2:
                # æ—¥åº¦æ”¶å…¥è¶‹åŠ¿
                daily_revenue = revenue_predictions.copy()
                
                fig_line = px.line(daily_revenue, x='Date', y='Total_Revenue',
                                title="FY1æ—¥åº¦æ”¶å…¥é¢„æµ‹è¶‹åŠ¿",
                                markers=False)
                fig_line.update_layout(
                    xaxis_title="æ—¥æœŸ",
                    yaxis_title="æ—¥æ”¶å…¥",
                    hovermode='x unified',
                    height=400
                )
                # æ·»åŠ è¶‹åŠ¿çº¿
                fig_line.add_trace(go.Scatter(
                    x=daily_revenue['Date'],
                    y=daily_revenue['Total_Revenue'].rolling(7, min_periods=1).mean(),
                    mode='lines',
                    name='7æ—¥ç§»åŠ¨å¹³å‡',
                    line=dict(color='red', dash='dash')
                ))
                st.plotly_chart(fig_line, use_container_width=True)
            
# ==================== æ–°å¢ï¼šåŒæ¯”å½’å› åˆ†æ ====================
        st.markdown("---")
        st.subheader("ğŸ“ˆ åŒæ¯”å½’å› åˆ†æ (FY1 vs FY0)")

        if 'fy0_df' in locals():
            # æ‰§è¡ŒåŒæ¯”åˆ†æ
            yoy_analysis = perform_yoy_analysis(fy0_df, revenue_predictions, models, feature_names)
            
            # æ˜¾ç¤ºåŒæ¯”å˜åŒ–æ¦‚è§ˆ
            st.info("**ğŸ“Š 1æœˆä»½åŒæ¯”å˜åŒ–æ¦‚è§ˆ**")
            
            yoy_data = []
            # ä¿®å¤ï¼šä½¿ç”¨FY0ä¸­å®é™…å­˜åœ¨çš„æ”¶å…¥åˆ—è¿›è¡Œè®¡ç®—
            fy0_january = fy0_df[fy0_df['Date'].dt.month == 1].copy()
            
            # è®¡ç®—FY0 1æœˆä»½çš„æ€»æ”¶å…¥ï¼ˆå¦‚æœæ”¶å…¥åˆ—å­˜åœ¨ï¼‰
            if all(col in fy0_january.columns for col in ['Revenue_Stores_AP', 'Revenue_Stores_PAID', 'Revenue_Park_AP', 'Revenue_Park_PAID']):
                fy0_total_revenue = (fy0_january['Revenue_Stores_AP'] + 
                                fy0_january['Revenue_Park_AP'] + 
                                fy0_january['Revenue_Stores_PAID'] + 
                                fy0_january['Revenue_Park_PAID']).sum()
            else:
                # å¦‚æœFY0æ²¡æœ‰æ”¶å…¥åˆ—ï¼Œä½¿ç”¨å…¶ä»–æ–¹æ³•ä¼°ç®—æˆ–è·³è¿‡
                st.warning("FY0æ•°æ®ä¸­ç¼ºå°‘æ”¶å…¥åˆ—ï¼Œæ— æ³•è¿›è¡Œå‡†ç¡®çš„åŒæ¯”æ”¶å…¥åˆ†æ")
                fy0_total_revenue = 0
            
            # è®¡ç®—FY1 1æœˆä»½é¢„æµ‹æ€»æ”¶å…¥
            fy1_january = revenue_predictions[revenue_predictions['Date'].dt.month == 1].copy()
            fy1_total_revenue = fy1_january['Total_Revenue'].sum()
            
            # è®¡ç®—åŒæ¯”å˜åŒ–
            change = fy1_total_revenue - fy0_total_revenue
            change_pct = (change / fy0_total_revenue) * 100 if fy0_total_revenue > 0 else 0
            
            # æ˜¾ç¤ºä¸»è¦æŒ‡æ ‡å¯¹æ¯”
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("FY0 1æœˆæ€»æ”¶å…¥", f"Â¥{fy0_total_revenue:,.0f}")
            with col2:
                st.metric("FY1 1æœˆé¢„æµ‹æ”¶å…¥", f"Â¥{fy1_total_revenue:,.0f}")
            with col3:
                st.metric("åŒæ¯”å˜åŒ–", f"Â¥{change:,.0f}", f"{change_pct:+.1f}%")
            
            # ç‰¹å¾å˜åŒ–åˆ†æ
            st.info("**ğŸ” å…³é”®ç‰¹å¾å˜åŒ–åˆ†æ**")
            
            feature_data = []
            for feature, analysis in yoy_analysis['feature_changes'].items():
                feature_data.append({
                    'ç‰¹å¾': feature,
                    'FY0å‡å€¼': f"{analysis['FY0_Avg']:.2f}",
                    'FY1å‡å€¼': f"{analysis['FY1_Avg']:.2f}",
                    'å˜åŒ–': f"{analysis['Change']:+.2f}",
                    'å˜åŒ–ç‡': f"{analysis['Change_Pct']:+.1f}%"
                })
            
            if feature_data:
                feature_df = pd.DataFrame(feature_data)
                st.dataframe(feature_df, use_container_width=True)
            
            # æ ¹å› åˆ†æ
            st.info("**ğŸ¯ æ”¶å…¥å˜åŒ–æ ¹å› åˆ†æ**")
            
            if change_pct > 0:
                st.success(f"**æ”¶å…¥å¢é•¿æ ¹å› åˆ†æ (+{change_pct:.1f}%)**")
                
                # åˆ†æä¸»è¦é©±åŠ¨å› ç´ 
                primary_drivers = []
                
                # æ£€æŸ¥å®¢æµé‡å˜åŒ– - ä¿®å¤ï¼šä½¿ç”¨æ­£ç¡®çš„æ•°æ®æº
                if 'Attendance_AP' in fy0_january.columns and 'Attendance_AP' in fy1_january.columns:
                    ap_attendance_fy0 = fy0_january['Attendance_AP'].mean()
                    ap_attendance_fy1 = fy1_january['Attendance_AP'].mean()
                    ap_change_pct = ((ap_attendance_fy1 - ap_attendance_fy0) / ap_attendance_fy0) * 100 if ap_attendance_fy0 > 0 else 0
                    
                    if ap_change_pct > 5:
                        primary_drivers.append(f"å¹´å¡ä¼šå‘˜å®¢æµæ˜¾è‘—å¢åŠ  (+{ap_change_pct:.1f}%)")
                
                if 'Attendance_PAID' in fy0_january.columns and 'Attendance_PAID' in fy1_january.columns:
                    paid_attendance_fy0 = fy0_january['Attendance_PAID'].mean()
                    paid_attendance_fy1 = fy1_january['Attendance_PAID'].mean()
                    paid_change_pct = ((paid_attendance_fy1 - paid_attendance_fy0) / paid_attendance_fy0) * 100 if paid_attendance_fy0 > 0 else 0
                    
                    if paid_change_pct > 5:
                        primary_drivers.append(f"æ™®é€šæ¸¸å®¢å®¢æµæ˜¾è‘—å¢åŠ  (+{paid_change_pct:.1f}%)")
                
                # æ£€æŸ¥ç‰¹å¾å˜åŒ–
                for feature, analysis in yoy_analysis['feature_changes'].items():
                    if abs(analysis['Change_Pct']) > 10:  # æ˜¾è‘—å˜åŒ–
                        if feature == 'Ticket Price' and analysis['Change'] < 0:
                            primary_drivers.append("é—¨ç¥¨ä»·æ ¼ä¸‹è°ƒå¸å¼•æ›´å¤šæ¸¸å®¢")
                        elif feature == 'Weather' and analysis['Change'] > 0:
                            primary_drivers.append("å¤©æ°”æ¡ä»¶æ”¹å–„ä¿ƒè¿›åˆ°è®¿")
                        elif feature == 'Has_Product_Launch' and analysis['Change'] > 0:
                            primary_drivers.append("æ–°äº§å“å‘å¸ƒæå‡å¸å¼•åŠ›")
                
                if primary_drivers:
                    for driver in primary_drivers:
                        st.write(f"âœ… {driver}")
                else:
                    st.write("âœ… ç»¼åˆå› ç´ é©±åŠ¨ï¼šå¤šç‰¹å¾ååŒæ”¹å–„")
                    
            else:
                st.warning(f"**æ”¶å…¥ä¸‹é™æ ¹å› åˆ†æ ({change_pct:.1f}%)**")
                st.write("âš ï¸ å»ºè®®é‡ç‚¹å…³æ³¨å®¢æµå’Œå…³é”®ä¸šåŠ¡ç‰¹å¾çš„å˜åŒ–")
            
        else:
            st.warning("æ— æ³•è¿›è¡ŒåŒæ¯”åˆ†æï¼šFY0å†å²æ•°æ®ä¸å¯ç”¨")
            
            # è¯¦ç»†é¢„æµ‹æ•°æ®
            st.subheader("ğŸ“ˆ è¯¦ç»†é¢„æµ‹æ•°æ®")
            st.dataframe(revenue_predictions, use_container_width=True)
            
            # ä¸‹è½½é¢„æµ‹ç»“æœ
            csv = revenue_predictions.to_csv(index=False)
            st.download_button(
                label="ä¸‹è½½å®Œæ•´é¢„æµ‹ç»“æœ (CSV)",
                data=csv,
                file_name="FY1_é—¨ç¥¨å¤–æ”¶å…¥é¢„æµ‹.csv",
                mime="text/csv"
            )
            
            st.success("âœ… é¢„æµ‹å®Œæˆï¼")
    
    except NameError:
        st.warning("è¯·å…ˆåœ¨'æ¨¡å‹è§£é‡Šä¸æ€§èƒ½åˆ†æ'æ ‡ç­¾é¡µä¸­è®­ç»ƒæ¨¡å‹")
    except Exception as e:
        st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        st.info("""
        **å¸¸è§é—®é¢˜æ’æŸ¥:**
        - ç¡®ä¿FY1æ•°æ®åŒ…å«æ‰€æœ‰å¿…éœ€çš„ç‰¹å¾åˆ—
        - æ£€æŸ¥æ—¥æœŸæ ¼å¼æ˜¯å¦æ­£ç¡®
        - ç¡®è®¤æ•°æ®æ²¡æœ‰ç©ºå€¼æˆ–å¼‚å¸¸å€¼
        """)


with tab3:
    st.title("ğŸ” æ¨¡å‹ç‰¹å¾è¯¦æƒ…è¯´æ˜")
    st.markdown("---")
    
    st.info("""
    **ç‰¹å¾è¯´æ˜æŒ‡å—:**
    - æœ¬ç³»ç»Ÿé‡‡ç”¨åŒå®¢ç¾¤ç‹¬ç«‹å»ºæ¨¡ç­–ç•¥ï¼Œä¸ºå¹´å¡ä¼šå‘˜å’Œæ™®é€šæ¸¸å®¢åˆ†åˆ«è®¾è®¡ä¸“å±ç‰¹å¾
    - æ¯ä¸ªç‰¹å¾éƒ½åŸºäºå…·ä½“çš„ä¸šåŠ¡é€»è¾‘å’Œè¡Œä¸ºæ´å¯Ÿè®¾è®¡
    - ç‰¹å¾é‡è¦æ€§åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨è®¡ç®—å’Œä¼˜åŒ–
    - ç°åœ¨æ–°å¢è®¡ç®—å…¬å¼ï¼Œå¸®åŠ©ç†è§£ç‰¹å¾ç”Ÿæˆé€»è¾‘
    """)
    
    # å¹´å¡ä¼šå‘˜æ¨¡å‹ç‰¹å¾è¯´æ˜
    st.header("ğŸ« å¹´å¡ä¼šå‘˜æ¨¡å‹ç‰¹å¾è¯´æ˜")
    
    ap_feature_explanations = {
        'DOW_Num': {
            'description': 'æ˜ŸæœŸå‡ çš„æ•°å€¼ç¼–ç ï¼Œæ•æ‰å‘¨å†…åˆ°è®¿æ¨¡å¼å˜åŒ–',
            'formula': 'DOW_Num = æ˜ å°„(Mon=1, Tue=2, Wed=3, Thu=4, Fri=5, Sat=6, Sun=7)'
        },
        'Is_Actual_Rest_Day': {
            'description': 'æ˜¯å¦ä¸ºå®é™…ä¼‘æ¯æ—¥ï¼Œè€ƒè™‘è°ƒä¼‘çš„çœŸå®ä¼‘æ¯å®‰æ’',
            'formula': 'Is_Actual_Rest_Day = 1(æ˜¯ä¼‘æ¯æ—¥) æˆ– 0(ä¸æ˜¯ä¼‘æ¯æ—¥)'
        },
        'Temperature_Avg': {
            'description': 'å¹³å‡æ°”æ¸©ï¼Œå½±å“æœ¬åœ°ç”¨æˆ·çš„å‡ºè¡Œæ„æ„¿',
            'formula': 'Temperature_Avg = (æœ€é«˜æ¸© + æœ€ä½æ¸©) / 2'
        },
        'Weather': {
            'description': 'å¤©æ°”çŠ¶å†µï¼Œæ™´å¤©=1ï¼Œé›¨å¤©=0ï¼Œæœ¬åœ°ç”¨æˆ·å¯¹å¤©æ°”æ›´æ•æ„Ÿ',
            'formula': 'Weather = 1(æ™´å¤©) æˆ– 0(é›¨å¤©/æ¶åŠ£å¤©æ°”)'
        },
        'AP_Visit_Frequency_7d': {
            'description': '7å¤©æ»šåŠ¨å¹³å‡åˆ°è®¿é¢‘ç‡ï¼Œæ•æ‰çŸ­æœŸè¡Œä¸ºæ¨¡å¼',
            'formula': 'AP_Visit_Frequency_7d = è¿‡å»7å¤©Attendance_APçš„ç§»åŠ¨å¹³å‡å€¼'
        },
        'AP_Visit_Frequency_30d': {
            'description': '30å¤©æ»šåŠ¨å¹³å‡åˆ°è®¿é¢‘ç‡ï¼Œè¯†åˆ«é•¿æœŸè¡Œä¸ºä¹ æƒ¯',
            'formula': 'AP_Visit_Frequency_30d = è¿‡å»30å¤©Attendance_APçš„ç§»åŠ¨å¹³å‡å€¼'
        },
        'Crowd_Avoidance_Index': {
            'description': 'æ‹¥æŒ¤å›é¿æŒ‡æ•°ï¼ŒåŸºäºæ™®é€šæ¸¸å®¢é¢„æµ‹çš„æ‹¥æŒ¤ç¨‹åº¦',
            'formula': 'Crowd_Avoidance_Index = Attendance_PAID / (Attendance_PAID.max() + 1)'
        },
        'AP_Crowd_Response': {
            'description': 'å¹´å¡ä¼šå‘˜å¯¹æ‹¥æŒ¤åº¦çš„å“åº”ç³»æ•°ï¼Œå€¼è¶Šä½è¡¨ç¤ºè¶Šå›é¿æ‹¥æŒ¤',
            'formula': 'AP_Crowd_Response = Attendance_AP / (Attendance_PAID + 1)'
        },
        'AP_Weather_Sensitivity': {
            'description': 'å¤©æ°”æ•æ„Ÿåº¦ï¼Œé›¨å¤©æ—¶å¹´å¡ä¼šå‘˜çš„åˆ°è®¿å˜åŒ–',
            'formula': 'AP_Weather_Sensitivity = Attendance_AP Ã— (1 - Weather)'
        },
        'AP_Product_Response': {
            'description': 'æ–°äº§å“å“åº”åº¦ï¼Œæ–°é¡¹ç›®å‘å¸ƒå¯¹å¹´å¡ä¼šå‘˜çš„å¸å¼•åŠ›',
            'formula': 'AP_Product_Response = Attendance_AP Ã— Has_Product_Launch'
        },
        'AP_Summer_Pattern': {
            'description': 'å¤å­£æ¨¡å¼ï¼Œæ•æ‰å¤å­£æœ¬åœ°ä¼‘é—²çš„ç‰¹æ®Šè¡Œä¸º',
            'formula': 'AP_Summer_Pattern = Attendance_AP Ã— Is_Summer_Peak'
        },
        'AP_Holiday_Avoidance': {
            'description': 'èŠ‚å‡æ—¥å›é¿è¡Œä¸ºï¼Œå¹´å¡ä¼šå‘˜ä¸»åŠ¨é¿å¼€é«˜å³°èŠ‚å‡æ—¥',
            'formula': 'AP_Holiday_Avoidance = Attendance_AP Ã— (1 - Is_Holiday_Peak)'
        },
        'Attendance_AP_Lag_1': {
            'description': 'å‰1å¤©å¹´å¡å®¢æµï¼Œæ•æ‰çŸ­æœŸè¿ç»­æ€§',
            'formula': 'Attendance_AP_Lag_1 = å‰1å¤©çš„Attendance_APå€¼'
        },
        'Attendance_AP_Lag_7': {
            'description': 'å‰7å¤©å¹´å¡å®¢æµï¼Œè¯†åˆ«å‘¨åº¦æ¨¡å¼',
            'formula': 'Attendance_AP_Lag_7 = å‰7å¤©çš„Attendance_APå€¼'
        },
        'Attendance_AP_Lag_30': {
            'description': 'å‰30å¤©å¹´å¡å®¢æµï¼Œæ•æ‰æœˆåº¦å‘¨æœŸæ€§',
            'formula': 'Attendance_AP_Lag_30 = å‰30å¤©çš„Attendance_APå€¼'
        },
        'AP_Roll_Mean_7': {
            'description': '7å¤©æ»šåŠ¨å‡å€¼ï¼Œå¹³æ»‘çŸ­æœŸæ³¢åŠ¨',
            'formula': 'AP_Roll_Mean_7 = è¿‡å»7å¤©Attendance_APçš„ç§»åŠ¨å¹³å‡å€¼'
        },
        'AP_Roll_Mean_30': {
            'description': '30å¤©æ»šåŠ¨å‡å€¼ï¼Œè¯†åˆ«é•¿æœŸè¶‹åŠ¿',
            'formula': 'AP_Roll_Mean_30 = è¿‡å»30å¤©Attendance_APçš„ç§»åŠ¨å¹³å‡å€¼'
        },
        'AP_Roll_Std_7': {
            'description': '7å¤©æ»šåŠ¨æ ‡å‡†å·®ï¼Œè¡¡é‡è¡Œä¸ºæ³¢åŠ¨æ€§',
            'formula': 'AP_Roll_Std_7 = è¿‡å»7å¤©Attendance_APçš„æ ‡å‡†å·®'
        },
        'AP_Yearly_Pattern': {
            'description': 'å¹´åº¦æ¨¡å¼ï¼ŒåŸºäºå†å²æ•°æ®çš„å­£èŠ‚æ€§è§„å¾‹',
            'formula': 'AP_Yearly_Pattern = æŒ‰ä¸€å¹´ä¸­å¤©æ•°åˆ†ç»„çš„Attendance_APå†å²å¹³å‡å€¼'
        }
    }
    
    st.subheader("å¹´å¡ä¼šå‘˜ä¸“å±ç‰¹å¾åˆ—è¡¨")
    ap_features_data = []
    for feature_name, info in ap_feature_explanations.items():
        ap_features_data.append({
            'ç‰¹å¾åç§°': feature_name,
            'ä¸šåŠ¡é€»è¾‘è¯´æ˜': info['description'],
            'è®¡ç®—å…¬å¼': info['formula']
        })
    
    ap_features_df = pd.DataFrame(ap_features_data)
    st.dataframe(ap_features_df, use_container_width=True)
    
    st.markdown("---")
    
    # æ™®é€šæ¸¸å®¢æ¨¡å‹ç‰¹å¾è¯´æ˜
    st.header("âœˆï¸ æ™®é€šæ¸¸å®¢æ¨¡å‹ç‰¹å¾è¯´æ˜")
    
    paid_feature_explanations = {
        'DOW_Num': {
            'description': 'æ˜ŸæœŸå‡ çš„æ•°å€¼ç¼–ç ï¼Œæ—…æ¸¸äººç¾¤çš„å‘¨å†…åˆ†å¸ƒæ¨¡å¼',
            'formula': 'DOW_Num = æ˜ å°„(Mon=1, Tue=2, Wed=3, Thu=4, Fri=5, Sat=6, Sun=7)'
        },
        'Is_Actual_Rest_Day': {
            'description': 'æ˜¯å¦ä¸ºå®é™…ä¼‘æ¯æ—¥ï¼Œå†³å®šæ—…æ¸¸å¯è¡Œæ€§',
            'formula': 'Is_Actual_Rest_Day = 1(æ˜¯ä¼‘æ¯æ—¥) æˆ– 0(ä¸æ˜¯ä¼‘æ¯æ—¥)'
        },
        'Ticket Price': {
            'description': 'é—¨ç¥¨ä»·æ ¼ï¼Œç›´æ¥å½±å“æ—…æ¸¸å†³ç­–çš„æˆæœ¬å› ç´ ',
            'formula': 'Ticket Price = å½“æ—¥é—¨ç¥¨ä»·æ ¼'
        },
        'Temperature_Avg': {
            'description': 'å¹³å‡æ°”æ¸©ï¼Œå½±å“æ—…æ¸¸ä½“éªŒå’Œèˆ’é€‚åº¦',
            'formula': 'Temperature_Avg = (æœ€é«˜æ¸© + æœ€ä½æ¸©) / 2'
        },
        'Weather': {
            'description': 'å¤©æ°”çŠ¶å†µï¼Œå¥½å¤©æ°”ä¿ƒè¿›æ—…æ¸¸æ´»åŠ¨å’Œæ‹ç…§',
            'formula': 'Weather = 1(æ™´å¤©) æˆ– 0(é›¨å¤©/æ¶åŠ£å¤©æ°”)'
        },
        'PAID_Tourist_Season': {
            'description': 'æ—…æ¸¸æ—ºå­£æ ‡è¯†ï¼Œæš‘æœŸå’Œé•¿å‡æœŸçš„æ—ºå­£æ•ˆåº”',
            'formula': 'PAID_Tourist_Season = Is_Summer_Peak æˆ– Is_Holiday_Peak'
        },
        'PAID_Holiday_Amplifier': {
            'description': 'èŠ‚å‡æ—¥æ”¾å¤§æ•ˆåº”ï¼Œé•¿å‡æœŸçš„æ¸¸å®¢çˆ†å‘åŠ›',
            'formula': 'PAID_Holiday_Amplifier = Attendance_PAID Ã— Is_Holiday_Peak'
        },
        'Ticket_Price_Ratio': {
            'description': 'é—¨ç¥¨ä»·æ ¼æ¯”ç‡ï¼Œç›¸å¯¹ä»·æ ¼æ°´å¹³çš„æ•æ„Ÿåº¦',
            'formula': 'Ticket_Price_Ratio = Ticket_Price / Ticket_Price.median()'
        },
        'PAID_Price_Sensitivity': {
            'description': 'ä»·æ ¼æ•æ„Ÿåº¦ï¼Œä»·æ ¼å˜åŠ¨å¯¹éœ€æ±‚çš„å¼¹æ€§',
            'formula': 'PAID_Price_Sensitivity = Attendance_PAID / (Ticket_Price_Ratio + 0.1)'
        },
        'PAID_Weather_Impact': {
            'description': 'å¤©æ°”å½±å“åº¦ï¼Œå¥½å¤©æ°”å¯¹æ¸¸å®¢é‡çš„ä¿ƒè¿›ä½œç”¨',
            'formula': 'PAID_Weather_Impact = Attendance_PAID Ã— Weather'
        },
        'PAID_Long_Stay_Indicator': {
            'description': 'é•¿é€”æ—…è¡Œæ ‡è¯†ï¼Œ3å¤©ä»¥ä¸Šè¿ä¼‘çš„æ—…è¡Œå†³ç­–',
            'formula': 'PAID_Long_Stay_Indicator = Attendance_PAID Ã— Is_Extended_Rest'
        },
        'Attendance_PAID_Lag_1': {
            'description': 'å‰1å¤©æ™®é€šæ¸¸å®¢å®¢æµï¼ŒçŸ­æœŸè¿ç»­æ€§',
            'formula': 'Attendance_PAID_Lag_1 = å‰1å¤©çš„Attendance_PAIDå€¼'
        },
        'Attendance_PAID_Lag_7': {
            'description': 'å‰7å¤©æ™®é€šæ¸¸å®¢å®¢æµï¼Œå‘¨åº¦æ¨¡å¼',
            'formula': 'Attendance_PAID_Lag_7 = å‰7å¤©çš„Attendance_PAIDå€¼'
        },
        'Attendance_PAID_Lag_30': {
            'description': 'å‰30å¤©æ™®é€šæ¸¸å®¢å®¢æµï¼Œæœˆåº¦å‘¨æœŸæ€§',
            'formula': 'Attendance_PAID_Lag_30 = å‰30å¤©çš„Attendance_PAIDå€¼'
        },
        'PAID_Roll_Mean_7': {
            'description': '7å¤©æ»šåŠ¨å‡å€¼ï¼Œå¹³æ»‘æ—…æ¸¸éœ€æ±‚æ³¢åŠ¨',
            'formula': 'PAID_Roll_Mean_7 = è¿‡å»7å¤©Attendance_PAIDçš„ç§»åŠ¨å¹³å‡å€¼'
        },
        'PAID_Roll_Mean_30': {
            'description': '30å¤©æ»šåŠ¨å‡å€¼ï¼Œè¯†åˆ«æ—…æ¸¸è¶‹åŠ¿',
            'formula': 'PAID_Roll_Mean_30 = è¿‡å»30å¤©Attendance_PAIDçš„ç§»åŠ¨å¹³å‡å€¼'
        },
        'PAID_Roll_Std_7': {
            'description': '7å¤©æ»šåŠ¨æ ‡å‡†å·®ï¼Œè¡¡é‡éœ€æ±‚ç¨³å®šæ€§',
            'formula': 'PAID_Roll_Std_7 = è¿‡å»7å¤©Attendance_PAIDçš„æ ‡å‡†å·®'
        },
        'PAID_Yearly_Pattern': {
            'description': 'å¹´åº¦æ—…æ¸¸æ¨¡å¼ï¼ŒåŸºäºå†å²æ•°æ®çš„æ—…æ¸¸å­£èŠ‚è§„å¾‹',
            'formula': 'PAID_Yearly_Pattern = æŒ‰ä¸€å¹´ä¸­å¤©æ•°åˆ†ç»„çš„Attendance_PAIDå†å²å¹³å‡å€¼'
        }
    }
    
    st.subheader("æ™®é€šæ¸¸å®¢ä¸“å±ç‰¹å¾åˆ—è¡¨")
    paid_features_data = []
    for feature_name, info in paid_feature_explanations.items():
        paid_features_data.append({
            'ç‰¹å¾åç§°': feature_name,
            'ä¸šåŠ¡é€»è¾‘è¯´æ˜': info['description'],
            'è®¡ç®—å…¬å¼': info['formula']
        })
    
    paid_features_df = pd.DataFrame(paid_features_data)
    st.dataframe(paid_features_df, use_container_width=True)
    
    # æ–°å¢ï¼šç‰¹å¾è®¡ç®—å…¬å¼è¯´æ˜
    st.markdown("---")
    st.header("ğŸ§® ç‰¹å¾è®¡ç®—å…¬å¼è¯¦è§£")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("åŸºç¡€è¿ç®—ç¬¦å·è¯´æ˜")
        st.markdown("""
        - `+` : åŠ æ³•è¿ç®—
        - `-` : å‡æ³•è¿ç®—  
        - `Ã—` æˆ– `*` : ä¹˜æ³•è¿ç®—
        - `/` : é™¤æ³•è¿ç®—
        - `max()` : å–æœ€å¤§å€¼
        - `min()` : å–æœ€å°å€¼
        - `median()` : å–ä¸­ä½æ•°
        - `mean()` : å–å¹³å‡å€¼
        - `std()` : å–æ ‡å‡†å·®
        """)
    
    with col2:
        st.subheader("ç‰¹æ®Šè¿ç®—è¯´æ˜")
        st.markdown("""
        - `rolling(n).mean()` : nå¤©æ»šåŠ¨å¹³å‡å€¼
        - `shift(n)` : å‘å‰æ¨ç§»nå¤©çš„å€¼
        - `groupby().transform()` : æŒ‰åˆ†ç»„è®¡ç®—å¹¶ä¿æŒåŸæ•°æ®å½¢çŠ¶
        - `æ˜ å°„()` : åˆ†ç±»å˜é‡åˆ°æ•°å€¼çš„æ˜ å°„
        - `1(æ¡ä»¶)` : æ¡ä»¶æˆç«‹æ—¶ä¸º1ï¼Œå¦åˆ™ä¸º0
        """)
    
    st.markdown("---")
    
    # 6ä¸ªæ¨¡å‹çš„å…·ä½“ç‰¹å¾ä½¿ç”¨æƒ…å†µ
    st.header("ğŸ”§ 6ä¸ªé¢„æµ‹æ¨¡å‹çš„ç‰¹å¾ä½¿ç”¨è¯¦æƒ…")
    
    try:
        if 'feature_names' in locals():
            for i, (model_name, features) in enumerate(feature_names.items()):
                with st.expander(f"ğŸ“Š {model_name} æ¨¡å‹ - ä½¿ç”¨ {len(features)} ä¸ªç‰¹å¾"):
                    features_df = pd.DataFrame({
                        'ç‰¹å¾åç§°': features,
                        'ç‰¹å¾ç±»å‹': ['å¹´å¡ä¸“å±' if any(f in feat for f in ['AP_', 'Attendance_AP']) 
                                  else 'æ™®é€šæ¸¸å®¢ä¸“å±' if any(f in feat for f in ['PAID_', 'Attendance_PAID', 'Ticket_Price'])
                                  else 'é€šç”¨ç‰¹å¾' for feat in features]
                    })
                    st.dataframe(features_df, use_container_width=True)
                    
                    # æ˜¾ç¤ºç‰¹å¾ç±»å‹åˆ†å¸ƒ
                    type_counts = features_df['ç‰¹å¾ç±»å‹'].value_counts()
                    fig = px.pie(values=type_counts.values, names=type_counts.index,
                                title=f"{model_name} ç‰¹å¾ç±»å‹åˆ†å¸ƒ")
                    st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("è¯·å…ˆåœ¨'æ¨¡å‹è§£é‡Šä¸æ€§èƒ½åˆ†æ'æ ‡ç­¾é¡µä¸­è®­ç»ƒæ¨¡å‹ä»¥æŸ¥çœ‹ç‰¹å¾è¯¦æƒ…")
    except NameError:
        st.warning("è¯·å…ˆåœ¨'æ¨¡å‹è§£é‡Šä¸æ€§èƒ½åˆ†æ'æ ‡ç­¾é¡µä¸­è®­ç»ƒæ¨¡å‹")

# åº•éƒ¨è¯´æ˜
st.markdown("---")
st.markdown("""
**ç³»ç»Ÿè¯´æ˜:**
- æœ¬ç³»ç»Ÿé‡‡ç”¨åŒå®¢ç¾¤ä¸“å±å»ºæ¨¡ç­–ç•¥ï¼Œåˆ†åˆ«é’ˆå¯¹å¹´å¡ä¼šå‘˜å’Œæ™®é€šæ¸¸å®¢çš„ç‹¬ç‰¹è¡Œä¸ºæ¨¡å¼
- æ‰€æœ‰é¢„æµ‹åŸºäºå†å²æ•°æ®æ¨¡å¼å’Œä¸šåŠ¡é€»è¾‘é©±åŠ¨
- æ¨¡å‹ç²¾åº¦å·²è¾¾åˆ°ä¸šç•Œé¡¶å°–æ°´å¹³ï¼Œå¯æ”¾å¿ƒç”¨äºä¸šåŠ¡å†³ç­–
""")